{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Prueba - SQL para Data Science__\n",
    "\n",
    "Desde __OkCupid__ -aplicación de citas- solicitan el desarrollo de una serie de modelos\n",
    "predictivos.\n",
    "\n",
    "Los datos a utilizar se registraron en base a una serie de perfiles públicos dentro de 25\n",
    "millas de la ciudad de San Francisco activos durante el 2011.\n",
    "\n",
    "__*Caveat*__: Los permisos para obtener estos datos provinieron del presidente y co-fundador de\n",
    "OkCupid, Christian Rudder, con la condición que se mantuvieran públicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos\n",
    "\n",
    "### Parte 1: Registro de los archivos en la base de datos.\n",
    "\n",
    "- Generar una nueva base de datos con la siguiente nomenclatura: apellido_nombre.\n",
    "- Importar en tablas los archivos `train_cupid.csv` y `test_cupid.csv` a un motor\n",
    "Postgres, __implementando sólo la librería `psycopg2`__. Las tablas deben contener los\n",
    "nombres de las columnas y el total de los registros presente en cada archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sqlalchemy import create_engine\n",
    "import joblib\n",
    "# Creamos la conexión a la base de datos\n",
    "conn = psycopg2.connect(\"user=postgres password=******\")\n",
    "conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la base de datos\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE DATABASE meneses_benjamin\")\n",
    "conn.commit()\n",
    "# Cerramos y nos conectamos a la base de datos creada\n",
    "cur.close()\n",
    "conn.close()\n",
    "conn = psycopg2.connect(\"dbname=meneses_benjamin user=postgres password=******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arreglo con nombre de las columnas\n",
    "csvHeader = \"age,height,virgo,taurus,scorpio,pisces,libra,leo,gemini,aries,aquarius,cancer,sagittarius,asian,hispanic / latin,black,indian,pacific islander,native american,middle eastern,colorado,new york,oregon,arizona,hawaii,montana,wisconsin,virginia,spain,nevada,illinois,vietnam,ireland,louisiana,michigan,texas,united kingdom,massachusetts,north carolina,idaho,mississippi,new jersey,florida,minnesota,georgia,utah,washington,west virginia,connecticut,tennessee,rhode island,district of columbia,canada,missouri,germany,pennsylvania,netherlands,switzerland,mexico,ohio,agnosticism,atheism,catholicism,buddhism,judaism,hinduism,islam,pro_dogs,pro_cats,spanish,chinese,french,german,single,seeing_someone,available,employed,income_between_25_50,income_between_50_75,income_over_75,drugs_often,drugs_sometimes,drinks_not at all,drinks_often,drinks_rarely,drinks_socially,drinks_very often,orientation_gay,orientation_straight,sex_m,smokes_sometimes,smokes_trying to quit,smokes_when drinking,smokes_yes,body_type_overweight,body_type_regular,education_high_school,education_undergrad_university\"\n",
    "tableCols = list(map(lambda x: x.replace(' ', '_').replace('/', ''), csvHeader.split(',')))\n",
    "# Construimos las tablas\n",
    "trainSql = \"CREATE TABLE train (id SERIAL PRIMARY KEY\"\n",
    "testSql = \"CREATE TABLE test (id SERIAL PRIMARY KEY\"\n",
    "for i, col in enumerate(tableCols):\n",
    "    trainSql += \", \"\n",
    "    testSql += \", \"\n",
    "    if i > 1:\n",
    "        trainSql += col + \" BOOLEAN NOT NULL\"\n",
    "        testSql += col + \" BOOLEAN NOT NULL\"\n",
    "    else:\n",
    "        trainSql += col + \" integer NOT NULL\"\n",
    "        testSql += col + \" integer NOT NULL\"\n",
    "trainSql += \");\"\n",
    "testSql += \");\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el cursor\n",
    "cur = conn.cursor()\n",
    "# Creamos la tabla train y conservamos los cambios\n",
    "cur.execute(trainSql)\n",
    "conn.commit()\n",
    "# Creamos la tabla test y conservamos los cambios\n",
    "cur.execute(testSql)\n",
    "conn.commit()\n",
    "# Cerramos el cursor\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion que lee el csv y lo pobla en la tabla train\n",
    "def csvToTable(fileName, columns, tableName):\n",
    "    cur = conn.cursor()\n",
    "    with open(fileName, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cur.execute(f\"INSERT INTO {tableName} ({', '.join(columns)}) VALUES ({', '.join(['%s' for i in columns])})\", [bool(int(float(val))) if i > 1 else int(float(val)) for i, val in enumerate(row)])\n",
    "    conn.commit()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    csvToTable('train_cupid.csv', tableCols, 'train')\n",
    "    csvToTable('test_cupid.csv', tableCols, 'test')\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(\"Error: unable to insert data\")\n",
    "    print(error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Entrenamiento de modelos (3.5 Puntos)\n",
    "- Ingestar la tabla de training __mediante__ `psycopg2` para el posterior entrenamiento del\n",
    "modelo.\n",
    "- Entrenar los siguientes modelos (sin necesidad de ajustar por hiper parámetros):\n",
    "   - `GradientBoostingClassifier`, `AdaBoostClassifer`,\n",
    "    `RandomForestClassifier`, `SVC`, `DecisionTreeClassifier`,\n",
    "    `LogisticRegression`, `BernoulliNB`.\n",
    "   - Existen tres vectores objetivos a evaluar: single, seeing someone y available.\n",
    "- Serializar el objeto y preservarlo por cada combinación de modelo entrenado y vector\n",
    "objetivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conseguimos la data de entrenamiento\n",
    "cur = conn.cursor()\n",
    "trainData = []\n",
    "try:\n",
    "    cur.execute(\"SELECT * FROM train;\")\n",
    "    trainData = cur.fetchall()\n",
    "    trainData = pd.DataFrame(trainData, columns=['id', *tableCols])\n",
    "    trainData = pd.concat([trainData.loc[:, ['age', 'height']], pd.get_dummies(trainData.loc[:, 'virgo':]).astype(np.int8)], axis=1)\n",
    "    cur.close()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(\"Error: unable to fetch data\")\n",
    "    print(error)\n",
    "    conn.rollback()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>virgo</th>\n",
       "      <th>taurus</th>\n",
       "      <th>scorpio</th>\n",
       "      <th>pisces</th>\n",
       "      <th>libra</th>\n",
       "      <th>leo</th>\n",
       "      <th>gemini</th>\n",
       "      <th>aries</th>\n",
       "      <th>...</th>\n",
       "      <th>orientation_straight</th>\n",
       "      <th>sex_m</th>\n",
       "      <th>smokes_sometimes</th>\n",
       "      <th>smokes_trying_to_quit</th>\n",
       "      <th>smokes_when_drinking</th>\n",
       "      <th>smokes_yes</th>\n",
       "      <th>body_type_overweight</th>\n",
       "      <th>body_type_regular</th>\n",
       "      <th>education_high_school</th>\n",
       "      <th>education_undergrad_university</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  height  virgo  taurus  scorpio  pisces  libra  leo  gemini  aries  \\\n",
       "0   35      70      0       0        0       0      0    0       0      0   \n",
       "1   38      68      0       0        0       0      0    0       0      0   \n",
       "2   23      71      0       0        0       1      0    0       0      0   \n",
       "3   29      66      0       0        0       0      0    0       0      0   \n",
       "4   29      67      0       1        0       0      0    0       0      0   \n",
       "\n",
       "   ...  orientation_straight  sex_m  smokes_sometimes  smokes_trying_to_quit  \\\n",
       "0  ...                     1      1                 0                      0   \n",
       "1  ...                     1      1                 0                      0   \n",
       "2  ...                     1      1                 0                      0   \n",
       "3  ...                     1      1                 0                      0   \n",
       "4  ...                     1      1                 0                      0   \n",
       "\n",
       "   smokes_when_drinking  smokes_yes  body_type_overweight  body_type_regular  \\\n",
       "0                     0           0                     0                  1   \n",
       "1                     0           0                     0                  1   \n",
       "2                     0           0                     0                  1   \n",
       "3                     0           0                     0                  0   \n",
       "4                     0           0                     0                  1   \n",
       "\n",
       "   education_high_school  education_undergrad_university  \n",
       "0                      0                               0  \n",
       "1                      0                               0  \n",
       "2                      0                               1  \n",
       "3                      0                               1  \n",
       "4                      0                               1  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos los modelos para cada vector objetivo\n",
    "targets = ['single', 'seeing_someone', 'available']\n",
    "modelsHash = {}\n",
    "X_train = trainData.drop(columns=targets)\n",
    "for col in targets:\n",
    "    modelsHash[col] = {}\n",
    "    y_train = trainData.loc[:, col]\n",
    "    modelsHash[col]['DecisionTree'] = DecisionTreeClassifier(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['RandomForest'] = RandomForestClassifier(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['AdaBoost'] = AdaBoostClassifier(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['GradientBoosting'] = GradientBoostingClassifier(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['SVC'] = SVC(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['LogisticRegression'] = LogisticRegression(random_state=19137, penalty='l2', solver='newton-cg', max_iter=500).fit(X_train, y_train)\n",
    "    modelsHash[col]['BernoulliNB'] = BernoulliNB().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: Exportación de predicciones (3.5 Puntos)\n",
    "- Ingestar la tabla de testing __mediante__ psycopg2 para la posterior predicción del\n",
    "modelo.\n",
    "- __En base a los objetos serializados__, predecir y evaluar cuatro queries específicas:\n",
    "   - __Query 1:__ 'atheism', 'asian', 'employed', 'pro_dogs', 'chinese'.\n",
    "   - __Query 2:__ 'income_over_75', 'french', 'german','orientation_straight', 'new york'.\n",
    "   - __Query 3:__ 'education_undergrad_university', 'body_type_regular', 'pro_dogs',\n",
    "'employed'.\n",
    "   - __Query 4:__ 'taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism'.\n",
    "- Cada una de estas queries específicas debe ser registrada en la base de datos.\n",
    "- La base de datos creada debe contener las tablas:\n",
    "   - 2 que representan a training y testing.\n",
    "   - 84 que representan a cada una de las combinaciones entre modelo, vector y\n",
    "query específica.\n",
    "- A modo de referencia, la base de datos creada debe contener 86 tablas en total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single\n",
      "\tDecisionTree\n",
      "\t\t0.9992530252477466\n",
      "\tRandomForest\n",
      "\t\t0.9992530252477466\n",
      "\tAdaBoost\n",
      "\t\t0.9200239031920721\n",
      "\tGradientBoosting\n",
      "\t\t0.9218166425974802\n",
      "\tSVC\n",
      "\t\t0.9198247099248046\n",
      "\tLogisticRegression\n",
      "\t\t0.9194263233902694\n",
      "\tBernoulliNB\n",
      "\t\t0.9136995169563269\n",
      "seeing_someone\n",
      "\tDecisionTree\n",
      "\t\t0.9996514117822818\n",
      "\tRandomForest\n",
      "\t\t0.9996514117822818\n",
      "\tAdaBoost\n",
      "\t\t0.9586175987251631\n",
      "\tGradientBoosting\n",
      "\t\t0.9588167919924306\n",
      "\tSVC\n",
      "\t\t0.9585678004083462\n",
      "\tLogisticRegression\n",
      "\t\t0.9585678004083462\n",
      "\tBernoulliNB\n",
      "\t\t0.9581196155569942\n",
      "available\n",
      "\tDecisionTree\n",
      "\t\t0.9996514117822818\n",
      "\tRandomForest\n",
      "\t\t0.9996514117822818\n",
      "\tAdaBoost\n",
      "\t\t0.9586175987251631\n",
      "\tGradientBoosting\n",
      "\t\t0.9588167919924306\n",
      "\tSVC\n",
      "\t\t0.9585678004083462\n",
      "\tLogisticRegression\n",
      "\t\t0.9585678004083462\n",
      "\tBernoulliNB\n",
      "\t\t0.9581196155569942\n"
     ]
    }
   ],
   "source": [
    "# Conseguimos la data de test\n",
    "cur = conn.cursor()\n",
    "testData = []\n",
    "try:\n",
    "    cur.execute(\"SELECT * FROM train;\")\n",
    "    testData = cur.fetchall()\n",
    "    testData = pd.DataFrame(testData, columns=['id', *tableCols])\n",
    "    testData = pd.concat([testData.loc[:, ['age', 'height']], pd.get_dummies(testData.loc[:, 'virgo':]).astype(np.int8)], axis=1)\n",
    "    cur.close()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(\"Error: unable to fetch data\")\n",
    "    print(error)\n",
    "    conn.rollback()\n",
    "    cur.close()\n",
    "X_test = testData.drop(columns=targets)\n",
    "# Definimos las utilidades para crear las tablas\n",
    "engine = create_engine('postgresql://postgres:******@localhost:5432/meneses_benjamin')\n",
    "def groupQuery(df, cols, target, tableName):\n",
    "    df = df.groupby(cols)[target].mean()\n",
    "    df.to_sql(tableName, con=engine, if_exists='replace')\n",
    "    return df\n",
    "# Iteramos sobre los modelos para cada vector objetivo\n",
    "for col in targets:\n",
    "    y_test = testData.loc[:, col]\n",
    "    print(f\"{col}\")\n",
    "    for model in modelsHash[col]:\n",
    "        print(f\"\\t{model}\")\n",
    "        print(f\"\\t\\t{modelsHash[col][model].score(X_test, y_test)}\")\n",
    "        model_name = f'{col}_{model}'\n",
    "        testData[model_name] = modelsHash[col][model].predict(X_test)\n",
    "        joblib.dump(modelsHash[col][model], f'models/{model_name}.pkl')\n",
    "        groupQuery(testData, ['atheism', 'asian', 'employed', 'pro_dogs', 'chinese'], model_name, f'query1_{model_name}')\n",
    "        groupQuery(testData, ['income_over_75', 'french', 'german', 'orientation_straight', 'new_york'], model_name, f'query2_{model_name}')\n",
    "        groupQuery(testData, ['education_undergrad_university', 'body_type_regular', 'pro_dogs', 'employed'], model_name, f'query3_{model_name}')\n",
    "        groupQuery(testData, ['taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism'], model_name, f'query4_{model_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
