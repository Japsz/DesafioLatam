{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Prueba - SQL para Data Science__\n",
    "\n",
    "Desde __OkCupid__ -aplicación de citas- solicitan el desarrollo de una serie de modelos\n",
    "predictivos.\n",
    "\n",
    "Los datos a utilizar se registraron en base a una serie de perfiles públicos dentro de 25\n",
    "millas de la ciudad de San Francisco activos durante el 2011.\n",
    "\n",
    "__*Caveat*__: Los permisos para obtener estos datos provinieron del presidente y co-fundador de\n",
    "OkCupid, Christian Rudder, con la condición que se mantuvieran públicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos\n",
    "\n",
    "### Parte 1: Registro de los archivos en la base de datos.\n",
    "\n",
    "- Generar una nueva base de datos con la siguiente nomenclatura: apellido_nombre.\n",
    "- Importar en tablas los archivos `train_cupid.csv` y `test_cupid.csv` a un motor\n",
    "Postgres, __implementando sólo la librería `psycopg2`__. Las tablas deben contener los\n",
    "nombres de las columnas y el total de los registros presente en cada archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Creamos la conexión a la base de datos\n",
    "conn = psycopg2.connect(\"user=postgres password=******\")\n",
    "conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la base de datos\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE DATABASE benjamin_meneses\")\n",
    "conn.commit()\n",
    "# Cerramos y nos conectamos a la base de datos creada\n",
    "cur.close()\n",
    "conn.close()\n",
    "conn = psycopg2.connect(\"dbname=benjamin_meneses user=postgres password=******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arreglo con nombre de las columnas\n",
    "csvHeader = \"age,height,virgo,taurus,scorpio,pisces,libra,leo,gemini,aries,aquarius,cancer,sagittarius,asian,hispanic / latin,black,indian,pacific islander,native american,middle eastern,colorado,new york,oregon,arizona,hawaii,montana,wisconsin,virginia,spain,nevada,illinois,vietnam,ireland,louisiana,michigan,texas,united kingdom,massachusetts,north carolina,idaho,mississippi,new jersey,florida,minnesota,georgia,utah,washington,west virginia,connecticut,tennessee,rhode island,district of columbia,canada,missouri,germany,pennsylvania,netherlands,switzerland,mexico,ohio,agnosticism,atheism,catholicism,buddhism,judaism,hinduism,islam,pro_dogs,pro_cats,spanish,chinese,french,german,single,seeing_someone,available,employed,income_between_25_50,income_between_50_75,income_over_75,drugs_often,drugs_sometimes,drinks_not at all,drinks_often,drinks_rarely,drinks_socially,drinks_very often,orientation_gay,orientation_straight,sex_m,smokes_sometimes,smokes_trying to quit,smokes_when drinking,smokes_yes,body_type_overweight,body_type_regular,education_high_school,education_undergrad_university\"\n",
    "tableCols = list(map(lambda x: x.replace(' ', '_').replace('/', ''), csvHeader.split(',')))\n",
    "# Construimos las tablas\n",
    "trainSql = \"CREATE TABLE train (id SERIAL PRIMARY KEY\"\n",
    "testSql = \"CREATE TABLE test (id SERIAL PRIMARY KEY\"\n",
    "for i, col in enumerate(tableCols):\n",
    "    trainSql += \", \"\n",
    "    testSql += \", \"\n",
    "    if i > 1:\n",
    "        trainSql += col + \" BOOLEAN NOT NULL\"\n",
    "        testSql += col + \" BOOLEAN NOT NULL\"\n",
    "    else:\n",
    "        trainSql += col + \" integer NOT NULL\"\n",
    "        testSql += col + \" integer NOT NULL\"\n",
    "trainSql += \");\"\n",
    "testSql += \");\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el cursor\n",
    "cur = conn.cursor()\n",
    "# Creamos la tabla train y conservamos los cambios\n",
    "cur.execute(trainSql)\n",
    "conn.commit()\n",
    "# Creamos la tabla test y conservamos los cambios\n",
    "cur.execute(testSql)\n",
    "conn.commit()\n",
    "# Cerramos el cursor\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los csv para poblar las tablas\n",
    "trainDf = pd.read_csv('train_cupid.csv')\n",
    "testDf = pd.read_csv('test_cupid.csv')\n",
    "# Recodificamos los booleanos\n",
    "trainDf[trainDf.columns[2:]] = trainDf[trainDf.columns[2:]].astype(bool)\n",
    "testDf[testDf.columns[2:]] = testDf[testDf.columns[2:]].astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "try:\n",
    "    # Insertamos los valores SQL\n",
    "    for index, row in trainDf.iterrows():\n",
    "        rowQuery = f\"INSERT INTO train ({', '.join(tableCols)}) VALUES (\"\n",
    "        rowQuery +=f\"{', '.join(['%s' for i in tableCols])});\\n\"\n",
    "        cur.execute(rowQuery, [str(val) if type(val) == 'bool' else val for val in row.values])\n",
    "    for index, row in testDf.iterrows():\n",
    "        rowQuery = f\"INSERT INTO test ({', '.join(tableCols)}) VALUES (\"\n",
    "        rowQuery +=f\"{', '.join(['%s' for i in tableCols])});\\n\"\n",
    "        cur.execute(rowQuery, [str(val) if type(val) == 'bool' else val for val in row.values])\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(\"Error: unable to insert data\")\n",
    "    print(error)\n",
    "    conn.rollback()\n",
    "    cur.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2: Entrenamiento de modelos (3.5 Puntos)\n",
    "- Ingestar la tabla de training __mediante__ `psycopg2` para el posterior entrenamiento del\n",
    "modelo.\n",
    "- Entrenar los siguientes modelos (sin necesidad de ajustar por hiper parámetros):\n",
    "   - `GradientBoostingClassifier`, `AdaBoostClassifer`,\n",
    "    `RandomForestClassifier`, `SVC`, `DecisionTreeClassifier`,\n",
    "    `LogisticRegression`, `BernoulliNB`.\n",
    "   - Existen tres vectores objetivos a evaluar: single, seeing someone y available.\n",
    "- Serializar el objeto y preservarlo por cada combinación de modelo entrenado y vector\n",
    "objetivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos los modelos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conseguimos la data de entrenamiento\n",
    "cur = conn.cursor()\n",
    "trainData = []\n",
    "try:\n",
    "    cur.execute(\"SELECT * FROM train;\")\n",
    "    trainData = cur.fetchall()\n",
    "    trainData = pd.DataFrame(trainData, columns=['id', *tableCols])\n",
    "    trainData = pd.concat([trainData.loc[:, ['age', 'height']], pd.get_dummies(trainData.loc[:, 'virgo':]).astype(np.int8)], axis=1)\n",
    "    cur.close()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(\"Error: unable to fetch data\")\n",
    "    print(error)\n",
    "    conn.rollback()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos los modelos para cada vector objetivo\n",
    "targets = ['single', 'seeing_someone', 'available']\n",
    "modelsHash = {}\n",
    "X_train = trainData.drop(columns=targets)\n",
    "for col in targets:\n",
    "    modelsHash[col] = {}\n",
    "    y_train = trainData.loc[:, col]\n",
    "    modelsHash[col]['DecisionTree'] = DecisionTreeClassifier(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['RandomForest'] = RandomForestClassifier(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['AdaBoost'] = AdaBoostClassifier(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['GradientBoosting'] = GradientBoostingClassifier(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['SVC'] = SVC(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['LogisticRegression'] = LogisticRegression(random_state=19137).fit(X_train, y_train)\n",
    "    modelsHash[col]['BernoulliNB'] = BernoulliNB().fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3: Exportación de predicciones (3.5 Puntos)\n",
    "- Ingestar la tabla de testing __mediante__ psycopg2 para la posterior predicción del\n",
    "modelo.\n",
    "- __En base a los objetos serializados__, predecir y evaluar cuatro queries específicas:\n",
    "   - __Query 1:__ 'atheism', 'asian', 'employed', 'pro_dogs', 'chinese'.\n",
    "   - __Query 2:__ 'income_over_75', 'french', 'german','orientation_straight', 'new york'.\n",
    "   - __Query 3:__ 'education_undergrad_university', 'body_type_regular', 'pro_dogs',\n",
    "'employed'.\n",
    "   - __Query 4:__ 'taurus', 'indian', 'washington', 'income_between_50_75', 'hinduism'.\n",
    "- Cada una de estas queries específicas debe ser registrada en la base de datos.\n",
    "- La base de datos creada debe contener las tablas:\n",
    "   - 2 que representan a training y testing.\n",
    "   - 84 que representan a cada una de las combinaciones entre modelo, vector y\n",
    "query específica.\n",
    "- A modo de referencia, la base de datos creada debe contener 86 tablas en total.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Query 1: WHERE atheism AND asian AND employed AND pro_dogs AND chinese\n",
      "single\n",
      "\tDecisionTree\n",
      "\t\t0.8333333333333334\n",
      "\tRandomForest\n",
      "\t\t0.8666666666666667\n",
      "\tAdaBoost\n",
      "\t\t0.8666666666666667\n",
      "\tGradientBoosting\n",
      "\t\t0.8666666666666667\n",
      "\tSVC\n",
      "\t\t0.8666666666666667\n",
      "\tLogisticRegression\n",
      "\t\t0.8666666666666667\n",
      "\tBernoulliNB\n",
      "\t\t0.9\n",
      "seeing_someone\n",
      "\tDecisionTree\n",
      "\t\t0.8333333333333334\n",
      "\tRandomForest\n",
      "\t\t0.9\n",
      "\tAdaBoost\n",
      "\t\t0.9\n",
      "\tGradientBoosting\n",
      "\t\t0.9\n",
      "\tSVC\n",
      "\t\t0.9\n",
      "\tLogisticRegression\n",
      "\t\t0.9\n",
      "\tBernoulliNB\n",
      "\t\t0.9\n",
      "available\n",
      "\tDecisionTree\n",
      "\t\t0.8333333333333334\n",
      "\tRandomForest\n",
      "\t\t0.9\n",
      "\tAdaBoost\n",
      "\t\t0.9\n",
      "\tGradientBoosting\n",
      "\t\t0.9\n",
      "\tSVC\n",
      "\t\t0.9\n",
      "\tLogisticRegression\n",
      "\t\t0.9\n",
      "\tBernoulliNB\n",
      "\t\t0.9\n",
      "====================\n",
      "Query 2: WHERE income_over_75 AND french AND german AND orientation_straight AND new_york\n",
      "====================\n",
      "Query 3: WHERE education_undergrad_university AND body_type_regular AND pro_dogs AND employed\n",
      "single\n",
      "\tDecisionTree\n",
      "\t\t0.8931383577052868\n",
      "\tRandomForest\n",
      "\t\t0.9516310461192351\n",
      "\tAdaBoost\n",
      "\t\t0.952755905511811\n",
      "\tGradientBoosting\n",
      "\t\t0.952755905511811\n",
      "\tSVC\n",
      "\t\t0.952755905511811\n",
      "\tLogisticRegression\n",
      "\t\t0.952755905511811\n",
      "\tBernoulliNB\n",
      "\t\t0.9510686164229472\n",
      "seeing_someone\n",
      "\tDecisionTree\n",
      "\t\t0.9308211473565804\n",
      "\tRandomForest\n",
      "\t\t0.9763779527559056\n",
      "\tAdaBoost\n",
      "\t\t0.9769403824521935\n",
      "\tGradientBoosting\n",
      "\t\t0.9763779527559056\n",
      "\tSVC\n",
      "\t\t0.9769403824521935\n",
      "\tLogisticRegression\n",
      "\t\t0.9769403824521935\n",
      "\tBernoulliNB\n",
      "\t\t0.9769403824521935\n",
      "available\n",
      "\tDecisionTree\n",
      "\t\t0.9308211473565804\n",
      "\tRandomForest\n",
      "\t\t0.9763779527559056\n",
      "\tAdaBoost\n",
      "\t\t0.9769403824521935\n",
      "\tGradientBoosting\n",
      "\t\t0.9763779527559056\n",
      "\tSVC\n",
      "\t\t0.9769403824521935\n",
      "\tLogisticRegression\n",
      "\t\t0.9769403824521935\n",
      "\tBernoulliNB\n",
      "\t\t0.9769403824521935\n",
      "====================\n",
      "Query 4: WHERE taurus AND indian AND washington AND income_between_50_75 AND hinduism\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"WHERE atheism AND asian AND employed AND pro_dogs AND chinese\",\n",
    "    \"WHERE income_over_75 AND french AND german AND orientation_straight AND new_york\",\n",
    "    \"WHERE education_undergrad_university AND body_type_regular AND pro_dogs AND employed\",\n",
    "    \"WHERE taurus AND indian AND washington AND income_between_50_75 AND hinduism\"\n",
    "]\n",
    "\n",
    "cur = conn.cursor()\n",
    "try:\n",
    "    for number, query in enumerate(queries):\n",
    "        print(\"=\"*20)\n",
    "        print(f\"Query {number+1}: {query}\")\n",
    "        cur.execute(f\"SELECT * FROM test {query};\")\n",
    "        data = cur.fetchall()\n",
    "        data = pd.DataFrame(data, columns=['id', *tableCols])\n",
    "        if len(data) == 0:\n",
    "            for col in targets:\n",
    "                for model in modelsHash[col]:\n",
    "                    cur.execute(f\"CREATE TABLE query{number + 1}_{col}_{model.lower()} (id_obs integer PRIMARY KEY, prediction BOOLEAN NOT NULL, FOREIGN KEY (id_obs) REFERENCES test (id));\")\n",
    "                    conn.commit()\n",
    "            continue\n",
    "        ids = data['id']\n",
    "        data = pd.concat([data.loc[:, ['age', 'height']], pd.get_dummies(data.loc[:, 'virgo':]).astype(np.int8)], axis=1)\n",
    "        X_test = data.drop(columns=targets)\n",
    "        for col in targets:\n",
    "            y_test = data.loc[:, col]\n",
    "            print(f\"{col}\")\n",
    "            for model in modelsHash[col]:\n",
    "                print(f\"\\t{model}\")\n",
    "                print(f\"\\t\\t{modelsHash[col][model].score(X_test, y_test)}\")\n",
    "                try:\n",
    "                    cur.execute(f\"CREATE TABLE query{number + 1}_{col}_{model.lower()} (id_obs integer PRIMARY KEY, prediction BOOLEAN NOT NULL, FOREIGN KEY (id_obs) REFERENCES test (id));\")\n",
    "                    conn.commit()\n",
    "                    for idx, id in ids.items():\n",
    "                        prediction = modelsHash[col][model].predict([X_test.iloc[idx]])[0]\n",
    "                        cur.execute(f\"INSERT INTO query{number + 1}_{col}_{model.lower()} (id_obs, prediction) VALUES (%s, %s);\", [id, bool(prediction)])\n",
    "                    conn.commit()\n",
    "                except (Exception, psycopg2.DatabaseError) as error:\n",
    "                    conn.rollback()\n",
    "                    print(f\"Error: unable to create table query{number + 1}_{col}_{model}\")\n",
    "                    print(error)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "except (Exception, psycopg2.DatabaseError) as error:\n",
    "    print(\"Error: unable to fetch data\")\n",
    "    print(error)\n",
    "    conn.rollback()\n",
    "    cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07efdcd4b820c98a756949507a4d29d7862823915ec7477944641bea022f4f62"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
